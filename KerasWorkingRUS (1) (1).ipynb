{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasWorkingRUS.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Br-IhmlqoZ-c",
        "colab_type": "code",
        "outputId": "60058649-a677-4489-ce80-3f833e86cfd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNImJqoZoefD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Dropout\n",
        "from keras import optimizers, metrics, backend as K\n",
        "\n",
        "VAL_MAXLEN = 16\n",
        "\n",
        "\n",
        "def truncated_acc(y_true, y_pred):\n",
        "    y_true = y_true[:, :VAL_MAXLEN, :]\n",
        "    y_pred = y_pred[:, :VAL_MAXLEN, :]\n",
        "    \n",
        "    acc = metrics.categorical_accuracy(y_true, y_pred)\n",
        "    return K.mean(acc, axis=-1)\n",
        "\n",
        "\n",
        "def truncated_loss(y_true, y_pred):\n",
        "    y_true = y_true[:, :VAL_MAXLEN, :]\n",
        "    y_pred = y_pred[:, :VAL_MAXLEN, :]\n",
        "    \n",
        "    loss = K.categorical_crossentropy(\n",
        "        target=y_true, output=y_pred, from_logits=False)\n",
        "    return K.mean(loss, axis=-1)\n",
        "\n",
        "\n",
        "def seq2seq(hidden_size, nb_input_chars, nb_target_chars):\n",
        "  \n",
        "    encoder_inputs = Input(shape=(None, nb_input_chars),\n",
        "                           name='encoder_data')\n",
        "    encoder_lstm = LSTM(hidden_size, recurrent_dropout=0.2,\n",
        "                        return_sequences=True, return_state=False,\n",
        "                        name='encoder_lstm_1')\n",
        "    encoder_outputs = encoder_lstm(encoder_inputs)\n",
        "    \n",
        "    encoder_lstm = LSTM(hidden_size, recurrent_dropout=0.2,\n",
        "                        return_sequences=False, return_state=True,\n",
        "                        name='encoder_lstm_2')\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_outputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_inputs = Input(shape=(None, nb_target_chars),\n",
        "                           name='decoder_data')\n",
        "    \n",
        "    decoder_lstm = LSTM(hidden_size, dropout=0.2, return_sequences=True,\n",
        "                        return_state=True, name='decoder_lstm')\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                         initial_state=encoder_states)\n",
        "    decoder_softmax = Dense(nb_target_chars, activation='softmax',\n",
        "                            name='decoder_softmax')\n",
        "    decoder_outputs = decoder_softmax(decoder_outputs)\n",
        "\n",
        "    \n",
        "    model = Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                  outputs=decoder_outputs)\n",
        "    \n",
        "    adam = optimizers.Adam(lr=0.001, decay=0.0)\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', truncated_acc, truncated_loss])\n",
        "    \n",
        "    encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "\n",
        "    decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "    decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_softmax(decoder_outputs)\n",
        "    decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs,\n",
        "                          outputs=[decoder_outputs] + decoder_states)\n",
        "\n",
        "    return model, encoder_model, decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z80EaeBFof02",
        "colab_type": "code",
        "outputId": "70ddcaee-a12f-42ce-d5f9-8a11034b8af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9eF7OX3AopWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import unidecode\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "SOS = '\\t' \n",
        "EOS = '*' \n",
        "chars = list('йцукенгшщзхъфывапролджэячсмитьбюёЙЦУКЕНГШЩЗХЪЭЖДЛОРПАВЫФЯЧСМИТЬБЮЁ')\n",
        "REMOVE_CHARS = '[#$%\"\\+@<=>!&,-.?:;()*\\[\\]^_`{|}~/\\d\\t\\n\\r\\x0b\\x0c]'\n",
        "\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \n",
        "    def __init__(self, chars):\n",
        "      self.chars = sorted(set(chars))\n",
        "      '''self.char2index = dict((c, i) for i, c in enumerate(self.chars))\n",
        "      self.index2char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "      self.size = len(self.chars)'''\n",
        "      vocab_to_int = {}\n",
        "      count = 0\n",
        "      for character in self.chars:\n",
        "        if character not in vocab_to_int:\n",
        "          vocab_to_int[character] = count\n",
        "          count += 1\n",
        "      self.char2index = vocab_to_int\n",
        "      self.index2char = {v: k for k, v in self.char2index.items()}\n",
        "      #self.index2char = dict((i, c) for i, c in enumerate(self.CHARS))\n",
        "      self.size = len(self.chars)\n",
        "    \n",
        "    def encode(self, C, nb_rows):\n",
        "      \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "          C: string, to be encoded.\n",
        "          nb_rows: Number of rows in the returned one-hot encoding. This is\n",
        "          used to keep the # of rows for each data the same via padding.\n",
        "        \"\"\"\n",
        "      x = np.zeros((nb_rows, len(self.chars)), dtype=np.float32)\n",
        "      for i, c in enumerate(C):\n",
        "        x[i, self.char2index[c]] = 1.0\n",
        "      return x\n",
        "    '''def encode(self, C, nb_rows):\n",
        "      onehot_encoded = []\n",
        "      for value in range(len(C)):\n",
        "        letter = [0 for _ in range(len(self.char2index))]\n",
        "        letter[value] = 1\n",
        "        onehot_encoded.append(letter)\n",
        "        onehotenc = np.array((onehot_encoded), dtype=np.float32)\n",
        "      return onehotenc''' \n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "          x: A vector or 2D array of probabilities or one-hot encodings,\n",
        "          or a vector of character indices (used with `calc_argmax=False`).\n",
        "          calc_argmax: Whether to find the character index with maximum\n",
        "          probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            indices = x.argmax(axis=-1)\n",
        "        else:\n",
        "            indices = x\n",
        "        chars = ''.join(self.index2char[ind] for ind in indices)\n",
        "        return indices, chars\n",
        "\n",
        "    def sample_multinomial(self, preds, temperature=1.0):\n",
        "        \"\"\"Sample index and character output from `preds`,\n",
        "        an array of softmax probabilities with shape (1, 1, nb_chars).\n",
        "        \"\"\"\n",
        "        # Reshaped to 1D array of shape (nb_chars,).\n",
        "        preds = np.reshape(preds, len(self.chars)).astype(np.float64)\n",
        "        preds = np.log(preds) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        probs = np.random.multinomial(1, preds, 1)\n",
        "        index = np.argmax(probs)\n",
        "        char  = self.index2char[index]\n",
        "        return index, char\n",
        "\n",
        "\n",
        "def read_text(data_path, list_of_books):\n",
        "    text = ''\n",
        "    for book in list_of_books:\n",
        "        file_path = os.path.join(data_path, book)\n",
        "        strings = open(file_path).read()\n",
        "        text += strings + ' '\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = [re.sub(REMOVE_CHARS, '', token)\n",
        "              for token in re.split(\"[-\\n ]\", text)]\n",
        "    return tokens\n",
        "\n",
        "    \n",
        "def add_speling_erors(token, error_rate):\n",
        "    \n",
        "    assert(0.0 <= error_rate < 1.0)\n",
        "    if len(token) < 3:\n",
        "        return token\n",
        "    rand = np.random.rand()\n",
        "   \n",
        "    prob = error_rate / 4.0\n",
        "    if rand < prob:\n",
        "        random_char_index = np.random.randint(len(token))\n",
        "        token = token[:random_char_index] + np.random.choice(chars) \\\n",
        "                + token[random_char_index + 1:]\n",
        "    elif prob < rand < prob * 2:\n",
        "       \n",
        "        random_char_index = np.random.randint(len(token))\n",
        "        token = token[:random_char_index] + token[random_char_index + 1:]\n",
        "    elif prob * 2 < rand < prob * 3:\n",
        "       \n",
        "        random_char_index = np.random.randint(len(token))\n",
        "        token = token[:random_char_index] + np.random.choice(chars) \\\n",
        "                + token[random_char_index:]\n",
        "    elif prob * 3 < rand < prob * 4:\n",
        "        \n",
        "        random_char_index = np.random.randint(len(token) - 1)\n",
        "        token = token[:random_char_index]  + token[random_char_index + 1] \\\n",
        "                + token[random_char_index] + token[random_char_index + 2:]\n",
        "    else:\n",
        "  \n",
        "        pass\n",
        "    return token\n",
        "\n",
        "\n",
        "def transform(tokens, maxlen, error_rate=0.3, shuffle=True):\n",
        "    \"\"\"Transform tokens into model inputs and targets.\n",
        "    All inputs and targets are padded to maxlen with EOS character.\n",
        "    \"\"\"\n",
        "    if shuffle:\n",
        "        print('Shuffling data.')\n",
        "        np.random.shuffle(tokens)\n",
        "    encoder_tokens = []\n",
        "    decoder_tokens = []\n",
        "    target_tokens = []\n",
        "    for token in tokens:\n",
        "        encoder = add_speling_erors(token, error_rate=error_rate)\n",
        "        encoder += EOS * (maxlen - len(encoder)) # Padded to maxlen.\n",
        "        encoder_tokens.append(encoder)\n",
        "    \n",
        "        decoder = SOS + token\n",
        "        decoder += EOS * (maxlen - len(decoder))\n",
        "        decoder_tokens.append(decoder)\n",
        "    \n",
        "        target = decoder[1:]\n",
        "        target += EOS * (maxlen - len(target))\n",
        "        target_tokens.append(target)\n",
        "        \n",
        "        assert(len(encoder) == len(decoder) == len(target))\n",
        "    return encoder_tokens, decoder_tokens, target_tokens\n",
        "\n",
        "\n",
        "def batch(tokens, maxlen, ctable, batch_size=128, reverse=False):\n",
        "    \"\"\"Split data into chunks of `batch_size` examples.\"\"\"\n",
        "    def generate(tokens, reverse):\n",
        "        while(True): # This flag yields an infinite generator.\n",
        "            for token in tokens:\n",
        "                if reverse:\n",
        "                    token = token[::-1]\n",
        "                yield token\n",
        "    \n",
        "    token_iterator = generate(tokens, reverse)\n",
        "    data_batch = np.zeros((batch_size, maxlen, ctable.size),\n",
        "                          dtype=np.float32)\n",
        "    while(True):\n",
        "        for i in range(batch_size):\n",
        "            token = next(token_iterator)\n",
        "            data_batch[i] = ctable.encode(token, maxlen)\n",
        "        yield data_batch\n",
        "\n",
        "\n",
        "def datagen(encoder_iter, decoder_iter, target_iter):\n",
        "    \"\"\"Utility function to load data into required model format.\"\"\"\n",
        "    inputs = zip(encoder_iter, decoder_iter)\n",
        "    while(True):\n",
        "        encoder_input, decoder_input = next(inputs)\n",
        "        target = next(target_iter)\n",
        "        yield ([encoder_input, decoder_input], target)\n",
        "\n",
        "\n",
        "def decode_sequences(inputs, targets, input_ctable, target_ctable,\n",
        "                     maxlen, reverse, encoder_model, decoder_model,\n",
        "                     nb_examples, sample_mode='argmax', random=True):\n",
        "    input_tokens = []\n",
        "    target_tokens = []\n",
        "    \n",
        "    if random:\n",
        "        indices = np.random.randint(0, len(inputs), nb_examples)\n",
        "    else:\n",
        "        indices = range(nb_examples)\n",
        "        \n",
        "    for index in indices:\n",
        "        input_tokens.append(inputs[index])\n",
        "        target_tokens.append(targets[index])\n",
        "    input_sequences = batch(input_tokens, maxlen, input_ctable,\n",
        "                            nb_examples, reverse)\n",
        "    input_sequences = next(input_sequences)\n",
        "    \n",
        "    # Procedure for inference mode (sampling):\n",
        "    # 1) Encode input and retrieve initial decoder state.\n",
        "    # 2) Run one step of decoder with this initial state\n",
        "    #    and a start-of-sequence character as target.\n",
        "    #    Output will be the next target character.\n",
        "    # 3) Repeat with the current target character and current states.\n",
        "\n",
        "    # Encode the input as state vectors.    \n",
        "    states_value = encoder_model.predict(input_sequences)\n",
        "    \n",
        "    # Create batch of empty target sequences of length 1 character.\n",
        "    target_sequences = np.zeros((nb_examples, 1, target_ctable.size))\n",
        "    # Populate the first element of target sequence\n",
        "    # with the start-of-sequence character.\n",
        "    target_sequences[:, 0, target_ctable.char2index[SOS]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences.\n",
        "    # Exit condition: either hit max character limit\n",
        "    # or encounter end-of-sequence character.\n",
        "    decoded_tokens = [''] * nb_examples\n",
        "    for _ in range(maxlen):\n",
        "        # `char_probs` has shape\n",
        "        # (nb_examples, 1, nb_target_chars)\n",
        "        char_probs, h, c = decoder_model.predict(\n",
        "            [target_sequences] + states_value)\n",
        "\n",
        "        # Reset the target sequences.\n",
        "        target_sequences = np.zeros((nb_examples, 1, target_ctable.size))\n",
        "\n",
        "        # Sample next character using argmax or multinomial mode.\n",
        "        sampled_chars = []\n",
        "        for i in range(nb_examples):\n",
        "            if sample_mode == 'argmax':\n",
        "                next_index, next_char = target_ctable.decode(\n",
        "                    char_probs[i], calc_argmax=True)\n",
        "            elif sample_mode == 'multinomial':\n",
        "                next_index, next_char = target_ctable.sample_multinomial(\n",
        "                    char_probs[i], temperature=0.5)\n",
        "            else:\n",
        "                raise Exception(\n",
        "                    \"`sample_mode` accepts `argmax` or `multinomial`.\")\n",
        "            decoded_tokens[i] += next_char\n",
        "            sampled_chars.append(next_char) \n",
        "            # Update target sequence with index of next character.\n",
        "            target_sequences[i, 0, next_index] = 1.0\n",
        "\n",
        "        stop_char = set(sampled_chars)\n",
        "        if len(stop_char) == 1 and stop_char.pop() == EOS:\n",
        "            break\n",
        "            \n",
        "        # Update states.\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    # Sampling finished.\n",
        "    input_tokens   = [re.sub('[%s]' % EOS, '', token)\n",
        "                      for token in input_tokens]\n",
        "    target_tokens  = [re.sub('[%s]' % EOS, '', token)\n",
        "                      for token in target_tokens]\n",
        "    decoded_tokens = [re.sub('[%s]' % EOS, '', token)\n",
        "                      for token in decoded_tokens]\n",
        "    return input_tokens, target_tokens, decoded_tokens\n",
        "\n",
        "\n",
        "def restore_model(path_to_full_model, hidden_size):\n",
        "    \"\"\"Restore model to construct the encoder and decoder.\"\"\"\n",
        "    model = load_model(path_to_full_model, custom_objects={\n",
        "        'truncated_acc': truncated_acc, 'truncated_loss': truncated_loss})\n",
        "    \n",
        "    encoder_inputs = model.input[0] # encoder_data\n",
        "    encoder_lstm1 = model.get_layer('encoder_lstm_1')\n",
        "    encoder_lstm2 = model.get_layer('encoder_lstm_2')\n",
        "    \n",
        "    encoder_outputs = encoder_lstm1(encoder_inputs)\n",
        "    _, state_h, state_c = encoder_lstm2(encoder_outputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "    encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1] # decoder_data\n",
        "    decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "    decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_lstm = model.get_layer('decoder_lstm')\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_softmax = model.get_layer('decoder_softmax')\n",
        "    decoder_outputs = decoder_softmax(decoder_outputs)\n",
        "    decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs,\n",
        "                          outputs=[decoder_outputs] + decoder_states)\n",
        "    return encoder_model, decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmOdPyw3rZo0",
        "colab_type": "code",
        "outputId": "2f0f821a-2c66-47be-d908-51f7b5a1def0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17853
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1234)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# from utils import CharacterTable, transform\n",
        "# from utils import batch, datagen, decode_sequences\n",
        "# from utils import read_text, tokenize\n",
        "# from model import seq2seq\n",
        "\n",
        "error_rate = 0.8\n",
        "hidden_size = 512\n",
        "nb_epochs = 100\n",
        "train_batch_size = 128\n",
        "val_batch_size = 256\n",
        "sample_mode = 'argmax'\n",
        "# Input sequences may optionally be reversed,\n",
        "# shown to increase performance by introducing\n",
        "# shorter term dependencies between source and target:\n",
        "# \"Learning to Execute\"\n",
        "# http://arxiv.org/abs/1410.4615\n",
        "# \"Sequence to Sequence Learning with Neural Networks\"\n",
        "# https://arxiv.org/abs/1409.3215\n",
        "reverse = True\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/RUSbooks' \n",
        "books = ['txt3.txt','txt4.txt','txt5.txt','txt6.txt','txt7.txt',\n",
        "               'txt8.txt','txt9.txt','txt11.txt','txt12.txt']\n",
        "val_books = ['txt5.txt']\n",
        "#test_sentence = 'Уақыт қана емдейтiн, ұзап барып айығатын, әзiрше үзiлмес шер'\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Prepare training data.\n",
        "    text  = read_text(data_path, books)\n",
        "    vocab = tokenize(text)\n",
        "    vocab = list(filter(None, set(vocab)))\n",
        "    \n",
        "    # `maxlen` is the length of the longest word in the vocabulary\n",
        "    # plus two SOS and EOS characters.\n",
        "    maxlen = max([len(token) for token in vocab]) + 2\n",
        "    train_encoder, train_decoder, train_target = transform(vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
        "    \n",
        "    print(train_encoder[:10])\n",
        "    print(train_decoder[:10])\n",
        "    print(train_target[:10])\n",
        "\n",
        "    input_chars = set(' '.join(train_encoder))\n",
        "    target_chars = set(' '.join(train_decoder))\n",
        "    nb_input_chars = len(input_chars)\n",
        "    nb_target_chars = len(target_chars)\n",
        "\n",
        "    print('Size of training vocabulary =', len(vocab))\n",
        "    print('Number of unique input characters:', nb_input_chars)\n",
        "    print('Number of unique target characters:', nb_target_chars)\n",
        "    print('Max sequence length in the training set:', maxlen)\n",
        "\n",
        "    # Prepare validation data.\n",
        "    text = read_text(data_path, val_books)\n",
        "    val_tokens = tokenize(text)\n",
        "    val_tokens = list(filter(None, val_tokens))\n",
        "\n",
        "    val_maxlen = max([len(token) for token in val_tokens]) + 2\n",
        "    val_encoder, val_decoder, val_target = transform(\n",
        "        val_tokens, maxlen, error_rate=error_rate, shuffle=False)\n",
        "    print(val_encoder[:10])\n",
        "    print(val_decoder[:10])\n",
        "    print(val_target[:10])\n",
        "    print('Number of non-unique validation tokens =', len(val_tokens))\n",
        "    print('Max sequence length in the validation set:', val_maxlen)\n",
        "\n",
        "    # Define training and evaluation configuration.\n",
        "    input_ctable  = CharacterTable(input_chars)\n",
        "    target_ctable = CharacterTable(target_chars)\n",
        "\n",
        "    train_steps = len(vocab) // train_batch_size\n",
        "    val_steps = len(val_tokens) // val_batch_size\n",
        "\n",
        "    # Compile the model.\n",
        "    model, encoder_model, decoder_model = seq2seq(\n",
        "        hidden_size, nb_input_chars, nb_target_chars)\n",
        "    print(model.summary())\n",
        "\n",
        "    # Train and evaluate.\n",
        "    for epoch in range(nb_epochs):\n",
        "        print('Main Epoch {:d}/{:d}'.format(epoch + 1, nb_epochs))\n",
        "    \n",
        "        train_encoder, train_decoder, train_target = transform(\n",
        "            vocab, maxlen, error_rate=error_rate, shuffle=True)\n",
        "        \n",
        "        train_encoder_batch = batch(train_encoder, maxlen, input_ctable,\n",
        "                                    train_batch_size, reverse)\n",
        "        train_decoder_batch = batch(train_decoder, maxlen, target_ctable,\n",
        "                                    train_batch_size)\n",
        "        train_target_batch  = batch(train_target, maxlen, target_ctable,\n",
        "                                    train_batch_size)    \n",
        "\n",
        "        val_encoder_batch = batch(val_encoder, maxlen, input_ctable,\n",
        "                                  val_batch_size, reverse)\n",
        "        val_decoder_batch = batch(val_decoder, maxlen, target_ctable,\n",
        "                                  val_batch_size)\n",
        "        val_target_batch  = batch(val_target, maxlen, target_ctable,\n",
        "                                  val_batch_size)\n",
        "    \n",
        "        train_loader = datagen(train_encoder_batch,\n",
        "                               train_decoder_batch, train_target_batch)\n",
        "        val_loader = datagen(val_encoder_batch,\n",
        "                             val_decoder_batch, val_target_batch)\n",
        "    \n",
        "        model.fit_generator(train_loader,\n",
        "                            steps_per_epoch=train_steps,\n",
        "                            epochs=1, verbose=1,\n",
        "                            validation_data=val_loader,\n",
        "                            validation_steps=val_steps)\n",
        "\n",
        "        # On epoch end - decode a batch of misspelled tokens from the\n",
        "        # validation set to visualize speller performance.\n",
        "        nb_tokens = 5\n",
        "        input_tokens, target_tokens, decoded_tokens = decode_sequences(\n",
        "            val_encoder, val_target, input_ctable, target_ctable,\n",
        "            maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
        "            sample_mode=sample_mode, random=True)\n",
        "        \n",
        "        print('-')\n",
        "        print('Input tokens:  ', input_tokens)\n",
        "        print('Decoded tokens:', decoded_tokens)\n",
        "        print('Target tokens: ', target_tokens)\n",
        "        print('-')\n",
        "        \n",
        "        # Save the model at end of each epoch.\n",
        "        model_file = '_'.join(['seq2seq', 'epoch', str(epoch + 1)]) + '.h5'\n",
        "        save_dir = 'checkpoints'\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        save_path = os.path.join(save_dir, model_file)\n",
        "        print('Saving full model to {:s}'.format(save_path))\n",
        "        model.save(save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['некич************************************', 'валдетелей*******************************', 'наитыми**********************************', 'побалум**********************************', 'Двояков**********************************', 'ОмуЕ*************************************', '«утешительынм»***************************', 'кип**************************************', 'Фонвизин\\xa0Д\\xa0ВИсеобщая*********************', 'предстоящем******************************']\n",
            "['\\tнекие***********************************', '\\tвладетелей******************************', '\\tнабитыми********************************', '\\tпобалуй*********************************', '\\tсвояков*********************************', '\\tОмут************************************', '\\t«утешительным»**************************', '\\tкипу************************************', '\\tФонвизин\\xa0Д\\xa0ИВсеобщая********************', '\\tпредстоящем*****************************']\n",
            "['некие************************************', 'владетелей*******************************', 'набитыми*********************************', 'побалуй**********************************', 'свояков**********************************', 'Омут*************************************', '«утешительным»***************************', 'кипу*************************************', 'Фонвизин\\xa0Д\\xa0ИВсеобщая*********************', 'предстоящем******************************']\n",
            "Size of training vocabulary = 51480\n",
            "Number of unique input characters: 115\n",
            "Number of unique target characters: 114\n",
            "Max sequence length in the training set: 41\n",
            "['\\ufeffE***************************************', 'M****************************************', 'Шавроав**********************************', 'пПтички**********************************', 'певЁчие**********************************', 'Спутники*********************************', 'Чехва************************************', 'Пд***************************************', 'ерд**************************************', 'В****************************************']\n",
            "['\\t\\ufeffE**************************************', '\\tM***************************************', '\\tШаврова*********************************', '\\tПтички**********************************', '\\tпевчие**********************************', '\\tСпутники********************************', '\\tЧехова**********************************', '\\tПод*************************************', '\\tред*************************************', '\\tВ***************************************']\n",
            "['\\ufeffE***************************************', 'M****************************************', 'Шаврова**********************************', 'Птички***********************************', 'певчие***********************************', 'Спутники*********************************', 'Чехова***********************************', 'Под**************************************', 'ред**************************************', 'В****************************************']\n",
            "Number of non-unique validation tokens = 2560\n",
            "Max sequence length in the validation set: 21\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_data (InputLayer)       (None, None, 115)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm_1 (LSTM)           (None, None, 512)    1286144     encoder_data[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_data (InputLayer)       (None, None, 114)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm_2 (LSTM)           [(None, 512), (None, 2099200     encoder_lstm_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 512),  1284096     decoder_data[0][0]               \n",
            "                                                                 encoder_lstm_2[0][1]             \n",
            "                                                                 encoder_lstm_2[0][2]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_softmax (Dense)         (None, None, 114)    58482       decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,727,922\n",
            "Trainable params: 4,727,922\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Main Epoch 1/100\n",
            "Shuffling data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 68s 169ms/step - loss: 0.7625 - acc: 0.8100 - truncated_acc: 0.5194 - truncated_loss: 1.8753 - val_loss: 0.4884 - val_acc: 0.8742 - val_truncated_acc: 0.6778 - val_truncated_loss: 1.2506\n",
            "-\n",
            "Input tokens:   ['каминыы', 'татарскоЪ', 'Эот', 'окну', 'лишнее']\n",
            "Decoded tokens: ['прата', 'прата', 'прата', 'прата', 'прата']\n",
            "Target tokens:  ['камины', 'татарское', 'Это', 'окну', 'лишнее']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_1.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm_2/while/Exit_2:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'encoder_lstm_2/while/Exit_3:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Main Epoch 2/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.6639 - acc: 0.8194 - truncated_acc: 0.5394 - truncated_loss: 1.6885 - val_loss: 0.4503 - val_acc: 0.8801 - val_truncated_acc: 0.6928 - val_truncated_loss: 1.1534\n",
            "-\n",
            "Input tokens:   ['и', 'мнС', 'учбеа', 'мы', 'Вами']\n",
            "Decoded tokens: ['сторовал', 'стали', 'сторовал', 'стали', 'стали']\n",
            "Target tokens:  ['и', 'мне', 'учеба', 'мы', 'Вами']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_2.h5\n",
            "Main Epoch 3/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.6393 - acc: 0.8262 - truncated_acc: 0.5567 - truncated_loss: 1.6267 - val_loss: 0.4191 - val_acc: 0.8960 - val_truncated_acc: 0.7336 - val_truncated_loss: 1.0733\n",
            "-\n",
            "Input tokens:   ['Салтыкова', 'на', 'в', 'объявчял', 'на']\n",
            "Decoded tokens: ['пристали', 'наворани', 'вырати', 'обравали', 'наворани']\n",
            "Target tokens:  ['Салтыкова', 'на', 'в', 'объявлял', 'на']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_3.h5\n",
            "Main Epoch 4/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.6166 - acc: 0.8379 - truncated_acc: 0.5867 - truncated_loss: 1.5680 - val_loss: 0.3457 - val_acc: 0.9173 - val_truncated_acc: 0.7883 - val_truncated_loss: 0.8854\n",
            "-\n",
            "Input tokens:   ['днВй', 'Поленька', 'Е', 'Нео', 'ссе']\n",
            "Decoded tokens: ['днов', 'Поленно', 'прово', 'постовал', 'соста']\n",
            "Target tokens:  ['дней', 'Поленька', 'Е', 'Небо', 'все']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_4.h5\n",
            "Main Epoch 5/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 162ms/step - loss: 0.5887 - acc: 0.8505 - truncated_acc: 0.6189 - truncated_loss: 1.4973 - val_loss: 0.3247 - val_acc: 0.9262 - val_truncated_acc: 0.8109 - val_truncated_loss: 0.8314\n",
            "-\n",
            "Input tokens:   ['ГХор', 'и', 'псуто', 'не', 'Софка']\n",
            "Decoded tokens: ['Соро', 'из', 'посту', 'него', 'Сока']\n",
            "Target tokens:  ['Хор', 'и', 'пусто', 'не', 'Софка']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_5.h5\n",
            "Main Epoch 6/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.5709 - acc: 0.8563 - truncated_acc: 0.6340 - truncated_loss: 1.4519 - val_loss: 0.3132 - val_acc: 0.9316 - val_truncated_acc: 0.8249 - val_truncated_loss: 0.8021\n",
            "-\n",
            "Input tokens:   ['оперетончые', 'подезда', 'стрШго', 'Полньке', 'подаил']\n",
            "Decoded tokens: ['оберет', 'подезда', 'строго', 'Польнек', 'подали']\n",
            "Target tokens:  ['опереточные', 'подъезда', 'строго', 'Поленьке', 'подали']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_6.h5\n",
            "Main Epoch 7/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.5411 - acc: 0.8651 - truncated_acc: 0.6563 - truncated_loss: 1.3764 - val_loss: 0.3419 - val_acc: 0.9248 - val_truncated_acc: 0.8074 - val_truncated_loss: 0.8746\n",
            "-\n",
            "Input tokens:   ['го', 'Пгушкинский', 'и', 'месяц', 'вАзлагал']\n",
            "Decoded tokens: ['горо', 'Поглики', 'из', 'меся', 'возлага']\n",
            "Target tokens:  ['его', 'Пушкинский', 'и', 'месяц', 'возлагал']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_7.h5\n",
            "Main Epoch 8/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.5420 - acc: 0.8666 - truncated_acc: 0.6601 - truncated_loss: 1.3791 - val_loss: 0.2438 - val_acc: 0.9508 - val_truncated_acc: 0.8739 - val_truncated_loss: 0.6240\n",
            "-\n",
            "Input tokens:   ['Чеохв', 'на', 'окнН', 'о', 'Из']\n",
            "Decoded tokens: ['проход', 'на', 'окне', 'о', 'за']\n",
            "Target tokens:  ['Чехов', 'на', 'окна', 'о', 'Из']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_8.h5\n",
            "Main Epoch 9/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.5253 - acc: 0.8704 - truncated_acc: 0.6698 - truncated_loss: 1.3369 - val_loss: 0.2809 - val_acc: 0.9433 - val_truncated_acc: 0.8547 - val_truncated_loss: 0.7184\n",
            "-\n",
            "Input tokens:   ['к', 'Ж', 'Шарова', 'делЛть', 'магаина']\n",
            "Decoded tokens: ['коро', 'проденно', 'провода', 'дельть', 'магани']\n",
            "Target tokens:  ['к', 'Ж', 'Шаврова', 'делать', 'магазина']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_9.h5\n",
            "Main Epoch 10/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 66s 163ms/step - loss: 0.5359 - acc: 0.8695 - truncated_acc: 0.6675 - truncated_loss: 1.3625 - val_loss: 0.2362 - val_acc: 0.9597 - val_truncated_acc: 0.8968 - val_truncated_loss: 0.6041\n",
            "-\n",
            "Input tokens:   ['посала', 'чтобС', 'отблесЦ', 'Б', 'садыу']\n",
            "Decoded tokens: ['посала', 'чето', 'отбесленные', 'XI', 'саду']\n",
            "Target tokens:  ['послала', 'чтобы', 'отблеск', 'Б', 'саду']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_10.h5\n",
            "Main Epoch 11/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.5120 - acc: 0.8748 - truncated_acc: 0.6811 - truncated_loss: 1.3028 - val_loss: 0.2785 - val_acc: 0.9394 - val_truncated_acc: 0.8448 - val_truncated_loss: 0.7133\n",
            "-\n",
            "Input tokens:   ['ГосударсМвенная', 'то', 'данво', 'чтобС', 'при']\n",
            "Decoded tokens: ['Государственная', 'тор', 'данов', 'чтоб', 'приста']\n",
            "Target tokens:  ['Государственная', 'той', 'давно', 'чтобы', 'при']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_11.h5\n",
            "Main Epoch 12/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.5348 - acc: 0.8692 - truncated_acc: 0.6667 - truncated_loss: 1.3607 - val_loss: 0.3043 - val_acc: 0.9393 - val_truncated_acc: 0.8446 - val_truncated_loss: 0.7785\n",
            "-\n",
            "Input tokens:   ['Чехво', 'рассказа', 'мии', 'С', 'знате']\n",
            "Decoded tokens: ['приводить', 'расска', 'мили', 'Со', 'знате']\n",
            "Target tokens:  ['Чехов', 'рассказа', 'ими', 'С', 'знает']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_12.h5\n",
            "Main Epoch 13/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.5239 - acc: 0.8700 - truncated_acc: 0.6686 - truncated_loss: 1.3333 - val_loss: 0.2484 - val_acc: 0.9517 - val_truncated_acc: 0.8763 - val_truncated_loss: 0.6360\n",
            "-\n",
            "Input tokens:   ['развалясь', 'петь', 'асшитых', 'Фгазовые', 'ЛИейкин']\n",
            "Decoded tokens: ['развался', 'петь', 'сошитых', 'поговоды', 'Лейкин']\n",
            "Target tokens:  ['развалясь', 'петь', 'расшитых', 'газовые', 'Лейкин']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_13.h5\n",
            "Main Epoch 14/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4957 - acc: 0.8795 - truncated_acc: 0.6931 - truncated_loss: 1.2610 - val_loss: 0.2567 - val_acc: 0.9455 - val_truncated_acc: 0.8605 - val_truncated_loss: 0.6569\n",
            "-\n",
            "Input tokens:   ['у', 'блоьны', 'волосатДый', 'не', 'С']\n",
            "Decoded tokens: ['у', 'блонь', 'волостатый', 'не', 'С']\n",
            "Target tokens:  ['у', 'больны', 'волосатый', 'не', 'С']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_14.h5\n",
            "Main Epoch 15/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.5096 - acc: 0.8759 - truncated_acc: 0.6837 - truncated_loss: 1.2976 - val_loss: 0.2744 - val_acc: 0.9470 - val_truncated_acc: 0.8641 - val_truncated_loss: 0.7028\n",
            "-\n",
            "Input tokens:   ['на', 'ечсать', 'пшеком', 'И', 'женьщина']\n",
            "Decoded tokens: ['на', 'честь', 'пошком', 'И', 'женьщина']\n",
            "Target tokens:  ['на', 'чесать', 'пешком', 'И', 'женщина']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_15.h5\n",
            "Main Epoch 16/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.5072 - acc: 0.8764 - truncated_acc: 0.6851 - truncated_loss: 1.2914 - val_loss: 0.2664 - val_acc: 0.9466 - val_truncated_acc: 0.8633 - val_truncated_loss: 0.6818\n",
            "-\n",
            "Input tokens:   ['тперь', 'низкатя', 'ёпотому', 'литературнЦый', 'ои']\n",
            "Decoded tokens: ['тереть', 'низкая', 'потому', 'литературный', 'ои']\n",
            "Target tokens:  ['теперь', 'низкая', 'потому', 'литературный', 'они']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_16.h5\n",
            "Main Epoch 17/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.5092 - acc: 0.8734 - truncated_acc: 0.6775 - truncated_loss: 1.2952 - val_loss: 0.2489 - val_acc: 0.9522 - val_truncated_acc: 0.8776 - val_truncated_loss: 0.6371\n",
            "-\n",
            "Input tokens:   ['пшиете', 'Чеохв', 'ЭНет', 'потемкха', 'сидит']\n",
            "Decoded tokens: ['пошете', 'Черов', 'Нете', 'потемках', 'сидит']\n",
            "Target tokens:  ['пишете', 'Чехов', 'Нет', 'потемках', 'сидит']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_17.h5\n",
            "Main Epoch 18/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.5097 - acc: 0.8734 - truncated_acc: 0.6774 - truncated_loss: 1.2964 - val_loss: 0.2494 - val_acc: 0.9511 - val_truncated_acc: 0.8748 - val_truncated_loss: 0.6384\n",
            "-\n",
            "Input tokens:   ['писпательских', 'Ыкрепкого', 'и', 'же', 'огромМыми']\n",
            "Decoded tokens: ['пристательс', 'покретить', 'и', 'жен', 'огромыми']\n",
            "Target tokens:  ['писательских', 'крепкого', 'и', 'же', 'огромными']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_18.h5\n",
            "Main Epoch 19/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.4940 - acc: 0.8817 - truncated_acc: 0.6986 - truncated_loss: 1.2565 - val_loss: 0.1950 - val_acc: 0.9680 - val_truncated_acc: 0.9180 - val_truncated_loss: 0.4982\n",
            "-\n",
            "Input tokens:   ['бойко', 'енй', 'НоЁь', 'ревте', 'с']\n",
            "Decoded tokens: ['бойко', 'ней', 'Нось', 'ревте', 'с']\n",
            "Target tokens:  ['бойко', 'ней', 'Ночь', 'ревет', 'с']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_19.h5\n",
            "Main Epoch 20/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4710 - acc: 0.8865 - truncated_acc: 0.7109 - truncated_loss: 1.1990 - val_loss: 0.2290 - val_acc: 0.9600 - val_truncated_acc: 0.8976 - val_truncated_loss: 0.5865\n",
            "-\n",
            "Input tokens:   ['самоЖй', 'Эколесо', 'с', 'сочинют', 'огромМыми']\n",
            "Decoded tokens: ['самой', 'показанные', 'с', 'сочинют', 'огромыми']\n",
            "Target tokens:  ['самой', 'колесо', 'с', 'сочиняют', 'огромными']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_20.h5\n",
            "Main Epoch 21/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.5002 - acc: 0.8771 - truncated_acc: 0.6869 - truncated_loss: 1.2733 - val_loss: 0.2863 - val_acc: 0.9394 - val_truncated_acc: 0.8449 - val_truncated_loss: 0.7330\n",
            "-\n",
            "Input tokens:   ['Что', 'страшное', 'в', 'грзяно', 'И']\n",
            "Decoded tokens: ['Что', 'страшное', 'в', 'грязно', 'И']\n",
            "Target tokens:  ['Что', 'страшное', 'в', 'грязно', 'И']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_21.h5\n",
            "Main Epoch 22/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4916 - acc: 0.8799 - truncated_acc: 0.6939 - truncated_loss: 1.2513 - val_loss: 0.2033 - val_acc: 0.9659 - val_truncated_acc: 0.9128 - val_truncated_loss: 0.5200\n",
            "-\n",
            "Input tokens:   ['он', 'остался', 'за', 'в', 'с']\n",
            "Decoded tokens: ['оне', 'остался', 'за', 'в', 'с']\n",
            "Target tokens:  ['он', 'остался', 'за', 'в', 'с']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_22.h5\n",
            "Main Epoch 23/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4755 - acc: 0.8834 - truncated_acc: 0.7028 - truncated_loss: 1.2107 - val_loss: 0.2555 - val_acc: 0.9458 - val_truncated_acc: 0.8612 - val_truncated_loss: 0.6538\n",
            "-\n",
            "Input tokens:   ['ент', 'Низданные', 'Нт', 'спрашиает', 'шнурком']\n",
            "Decoded tokens: ['нет', 'Низданные', 'Нат', 'спрашиет', 'шурком']\n",
            "Target tokens:  ['нет', 'Неизданные', 'Нот', 'спрашивает', 'шнурком']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_23.h5\n",
            "Main Epoch 24/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4784 - acc: 0.8850 - truncated_acc: 0.7070 - truncated_loss: 1.2170 - val_loss: 0.2358 - val_acc: 0.9531 - val_truncated_acc: 0.8799 - val_truncated_loss: 0.6029\n",
            "-\n",
            "Input tokens:   ['еще', 'сытОсти', 'холисток', 'свя', 'их']\n",
            "Decoded tokens: ['щещ', 'сытитст', 'холисток', 'свя', 'их']\n",
            "Target tokens:  ['еще', 'сытости', 'хористок', 'вся', 'их']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_24.h5\n",
            "Main Epoch 25/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4668 - acc: 0.8859 - truncated_acc: 0.7092 - truncated_loss: 1.1878 - val_loss: 0.1924 - val_acc: 0.9660 - val_truncated_acc: 0.9129 - val_truncated_loss: 0.4923\n",
            "-\n",
            "Input tokens:   ['ходщить', 'проесхала', 'то', 'Пиьсма', 'атк']\n",
            "Decoded tokens: ['ходить', 'просехала', 'то', 'Письма', 'так']\n",
            "Target tokens:  ['ходить', 'проехала', 'то', 'Письма', 'так']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_25.h5\n",
            "Main Epoch 26/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4665 - acc: 0.8885 - truncated_acc: 0.7158 - truncated_loss: 1.1876 - val_loss: 0.2098 - val_acc: 0.9639 - val_truncated_acc: 0.9074 - val_truncated_loss: 0.5372\n",
            "-\n",
            "Input tokens:   ['А', 'в', 'тЭо', 'На', 'содеэжателю']\n",
            "Decoded tokens: ['А', 'в', 'тол', 'На', 'содержателю']\n",
            "Target tokens:  ['А', 'в', 'Это', 'На', 'содержателю']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_26.h5\n",
            "Main Epoch 27/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4808 - acc: 0.8823 - truncated_acc: 0.7002 - truncated_loss: 1.2235 - val_loss: 0.1895 - val_acc: 0.9691 - val_truncated_acc: 0.9209 - val_truncated_loss: 0.4849\n",
            "-\n",
            "Input tokens:   ['онс', 'расстЩгнули', 'Внот', 'он', 'чеховским']\n",
            "Decoded tokens: ['онс', 'расстгнули', 'Вонт', 'он', 'чеховским']\n",
            "Target tokens:  ['нос', 'расстегнули', 'Вот', 'он', 'чеховским']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_27.h5\n",
            "Main Epoch 28/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4682 - acc: 0.8862 - truncated_acc: 0.7101 - truncated_loss: 1.1919 - val_loss: 0.1886 - val_acc: 0.9614 - val_truncated_acc: 0.9011 - val_truncated_loss: 0.4827\n",
            "-\n",
            "Input tokens:   ['Пиёшите', 'хочеося', 'в', 'В', 'Кроме']\n",
            "Decoded tokens: ['Пишите', 'хочеося', 'в', 'В', 'Кроме']\n",
            "Target tokens:  ['Пишите', 'хочется', 'в', 'В', 'Кроме']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_28.h5\n",
            "Main Epoch 29/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.4708 - acc: 0.8861 - truncated_acc: 0.7097 - truncated_loss: 1.1983 - val_loss: 0.2225 - val_acc: 0.9523 - val_truncated_acc: 0.8779 - val_truncated_loss: 0.5697\n",
            "-\n",
            "Input tokens:   ['а', 'с', 'цветит', 'мтне', 'ншпомнить']\n",
            "Decoded tokens: ['а', 'с', 'цветит', 'мотне', 'напомнить']\n",
            "Target tokens:  ['а', 'с', 'светит', 'мне', 'напомнить']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_29.h5\n",
            "Main Epoch 30/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4738 - acc: 0.8844 - truncated_acc: 0.7054 - truncated_loss: 1.2055 - val_loss: 0.2053 - val_acc: 0.9641 - val_truncated_acc: 0.9080 - val_truncated_loss: 0.5253\n",
            "-\n",
            "Input tokens:   ['еще', 'платьте', 'M', 'Извозчик', 'искуссва']\n",
            "Decoded tokens: ['щее', 'платьет', 'подобрения', 'Извозчик', 'искуссва']\n",
            "Target tokens:  ['еще', 'платье', 'M', 'Извозчик', 'искусства']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_30.h5\n",
            "Main Epoch 31/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4946 - acc: 0.8794 - truncated_acc: 0.6926 - truncated_loss: 1.2579 - val_loss: 0.2343 - val_acc: 0.9526 - val_truncated_acc: 0.8786 - val_truncated_loss: 0.6000\n",
            "-\n",
            "Input tokens:   ['огоьки', 'Чехлов', 'жгуече', 'таланат', 'город']\n",
            "Decoded tokens: ['огольки', 'Чехлов', 'жеучее', 'таланат', 'город']\n",
            "Target tokens:  ['огоньки', 'Чехов', 'жгучее', 'таланта', 'город']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_31.h5\n",
            "Main Epoch 32/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4659 - acc: 0.8855 - truncated_acc: 0.7082 - truncated_loss: 1.1864 - val_loss: 0.2170 - val_acc: 0.9575 - val_truncated_acc: 0.8912 - val_truncated_loss: 0.5558\n",
            "-\n",
            "Input tokens:   ['скатерти', 'Александрови', 'к', 'и', 'Лиетратурное']\n",
            "Decoded tokens: ['скатерти', 'Александрови', 'к', 'и', 'Литературное']\n",
            "Target tokens:  ['скатерти', 'Александрович', 'к', 'и', 'Литературное']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_32.h5\n",
            "Main Epoch 33/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4531 - acc: 0.8908 - truncated_acc: 0.7218 - truncated_loss: 1.1524 - val_loss: 0.2551 - val_acc: 0.9512 - val_truncated_acc: 0.8750 - val_truncated_loss: 0.6521\n",
            "-\n",
            "Input tokens:   ['в', 'волосатДый', 'пол', 'с', 'азвязанная']\n",
            "Decoded tokens: ['в', 'волосатый', 'пол', 'с', 'завязанная']\n",
            "Target tokens:  ['в', 'волосатый', 'поле', 'с', 'завязанная']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_33.h5\n",
            "Main Epoch 34/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4732 - acc: 0.8841 - truncated_acc: 0.7046 - truncated_loss: 1.2048 - val_loss: 0.2029 - val_acc: 0.9599 - val_truncated_acc: 0.8974 - val_truncated_loss: 0.5194\n",
            "-\n",
            "Input tokens:   ['обнимаешт', 'на', 'ехать', 'трупп', 'ттеняет']\n",
            "Decoded tokens: ['обнимает', 'на', 'ехать', 'трупп', 'теняет']\n",
            "Target tokens:  ['обнимает', 'на', 'ехать', 'труппы', 'оттеняет']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_34.h5\n",
            "Main Epoch 35/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4502 - acc: 0.8917 - truncated_acc: 0.7238 - truncated_loss: 1.1461 - val_loss: 0.2335 - val_acc: 0.9526 - val_truncated_acc: 0.8786 - val_truncated_loss: 0.5980\n",
            "-\n",
            "Input tokens:   ['гастроле', 'стороне', 'утчи', 'ныжно', 'слШились']\n",
            "Decoded tokens: ['гастроле', 'стороне', 'утчи', 'ныжно', 'слились']\n",
            "Target tokens:  ['гастролер', 'стороне', 'тучи', 'нужно', 'слились']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_35.h5\n",
            "Main Epoch 36/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4675 - acc: 0.8872 - truncated_acc: 0.7125 - truncated_loss: 1.1900 - val_loss: 0.1682 - val_acc: 0.9709 - val_truncated_acc: 0.9255 - val_truncated_loss: 0.4306\n",
            "-\n",
            "Input tokens:   ['А', 'оставшись', 'необ', 'Лтиература', 'егъ']\n",
            "Decoded tokens: ['А', 'оставшись', 'необ', 'простородно', 'его']\n",
            "Target tokens:  ['А', 'оставшись', 'небо', 'Литература', 'его']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_36.h5\n",
            "Main Epoch 37/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4367 - acc: 0.8954 - truncated_acc: 0.7334 - truncated_loss: 1.1117 - val_loss: 0.1927 - val_acc: 0.9598 - val_truncated_acc: 0.8970 - val_truncated_loss: 0.4935\n",
            "-\n",
            "Input tokens:   ['не', 'наКбережной', 'и', 'топает', 'лШтерной']\n",
            "Decoded tokens: ['не', 'набережной', 'и', 'топает', 'летерной']\n",
            "Target tokens:  ['не', 'набережной', 'и', 'топает', 'литерной']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_37.h5\n",
            "Main Epoch 38/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4538 - acc: 0.8897 - truncated_acc: 0.7189 - truncated_loss: 1.1563 - val_loss: 0.1589 - val_acc: 0.9734 - val_truncated_acc: 0.9319 - val_truncated_loss: 0.4067\n",
            "-\n",
            "Input tokens:   ['вы', 'оперетЗчный', 'победив', 'небрежно', 'разглядеь']\n",
            "Decoded tokens: ['вы', 'оперетчный', 'победив', 'небрежно', 'разгляде']\n",
            "Target tokens:  ['вы', 'опереточный', 'победив', 'небрежно', 'разглядеть']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_38.h5\n",
            "Main Epoch 39/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4531 - acc: 0.8924 - truncated_acc: 0.7257 - truncated_loss: 1.1532 - val_loss: 0.2078 - val_acc: 0.9626 - val_truncated_acc: 0.9042 - val_truncated_loss: 0.5310\n",
            "-\n",
            "Input tokens:   ['и', 'бблиотека', 'И', 'миронк', 'одЮу']\n",
            "Decoded tokens: ['и', 'блиотика', 'И', 'миронк', 'оду']\n",
            "Target tokens:  ['и', 'библиотека', 'И', 'мирок', 'одну']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_39.h5\n",
            "Main Epoch 40/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4472 - acc: 0.8941 - truncated_acc: 0.7301 - truncated_loss: 1.1377 - val_loss: 0.1998 - val_acc: 0.9701 - val_truncated_acc: 0.9234 - val_truncated_loss: 0.5114\n",
            "-\n",
            "Input tokens:   ['дргой', 'бархатных', 'рассшказ', 'из', 'сеырй']\n",
            "Decoded tokens: ['драгой', 'бархатных', 'рассшка', 'из', 'серый']\n",
            "Target tokens:  ['другой', 'бархатных', 'рассказ', 'из', 'серый']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_40.h5\n",
            "Main Epoch 41/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4757 - acc: 0.8848 - truncated_acc: 0.7065 - truncated_loss: 1.2107 - val_loss: 0.2407 - val_acc: 0.9606 - val_truncated_acc: 0.8990 - val_truncated_loss: 0.6149\n",
            "-\n",
            "Input tokens:   ['Уехове', 'разлЁожена', 'он', 'бранится', 'волнешния']\n",
            "Decoded tokens: ['Уехове', 'разложена', 'он', 'бранится', 'волнешния']\n",
            "Target tokens:  ['Чехове', 'разложена', 'он', 'бранится', 'волнения']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_41.h5\n",
            "Main Epoch 42/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4355 - acc: 0.8952 - truncated_acc: 0.7328 - truncated_loss: 1.1089 - val_loss: 0.2075 - val_acc: 0.9582 - val_truncated_acc: 0.8930 - val_truncated_loss: 0.5312\n",
            "-\n",
            "Input tokens:   ['советы', 'а', 'внимаине', 'до', 'ешя']\n",
            "Decoded tokens: ['советы', 'а', 'внимание', 'до', 'еош']\n",
            "Target tokens:  ['советы', 'а', 'внимание', 'до', 'шея']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_42.h5\n",
            "Main Epoch 43/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4631 - acc: 0.8884 - truncated_acc: 0.7155 - truncated_loss: 1.1783 - val_loss: 0.2969 - val_acc: 0.9426 - val_truncated_acc: 0.8530 - val_truncated_loss: 0.7591\n",
            "-\n",
            "Input tokens:   ['загорлелая', 'ялотная', 'он', 'вДном', 'в']\n",
            "Decoded tokens: ['загорле', 'подставить', 'он', 'веном', 'в']\n",
            "Target tokens:  ['загорелая', 'плотная', 'он', 'вином', 'в']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_43.h5\n",
            "Main Epoch 44/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4400 - acc: 0.8954 - truncated_acc: 0.7335 - truncated_loss: 1.1198 - val_loss: 0.1772 - val_acc: 0.9696 - val_truncated_acc: 0.9220 - val_truncated_loss: 0.4531\n",
            "-\n",
            "Input tokens:   ['Молсква', 'иОзучаться', 'нарядныПе', 'оправдачла', 'балгороднее']\n",
            "Decoded tokens: ['Молскав', 'изучаться', 'нарядные', 'оправдала', 'благороднее']\n",
            "Target tokens:  ['Москва', 'изучаться', 'нарядные', 'оправдала', 'благороднее']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_44.h5\n",
            "Main Epoch 45/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4568 - acc: 0.8895 - truncated_acc: 0.7184 - truncated_loss: 1.1632 - val_loss: 0.2126 - val_acc: 0.9574 - val_truncated_acc: 0.8907 - val_truncated_loss: 0.5444\n",
            "-\n",
            "Input tokens:   ['интересбно', 'запеырся', 'Даже', 'гланвое', 'голосов']\n",
            "Decoded tokens: ['интересно', 'заперся', 'Даже', 'гланове', 'голосов']\n",
            "Target tokens:  ['интересно', 'заперся', 'Даже', 'главное', 'голосов']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_45.h5\n",
            "Main Epoch 46/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4311 - acc: 0.8970 - truncated_acc: 0.7376 - truncated_loss: 1.0969 - val_loss: 0.1905 - val_acc: 0.9734 - val_truncated_acc: 0.9318 - val_truncated_loss: 0.4859\n",
            "-\n",
            "Input tokens:   ['компонцвки', 'вникнить', 'свевтает', 'одваться', 'поевстях']\n",
            "Decoded tokens: ['компон', 'вникнить', 'светает', 'одваться', 'повестях']\n",
            "Target tokens:  ['компоновки', 'вникнуть', 'светает', 'одеваться', 'повестях']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_46.h5\n",
            "Main Epoch 47/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4516 - acc: 0.8910 - truncated_acc: 0.7223 - truncated_loss: 1.1501 - val_loss: 0.1796 - val_acc: 0.9690 - val_truncated_acc: 0.9207 - val_truncated_loss: 0.4599\n",
            "-\n",
            "Input tokens:   ['Эот', 'ПисЯма', 'перы', 'Николай', 'те']\n",
            "Decoded tokens: ['Это', 'Писам', 'перы', 'Николай', 'те']\n",
            "Target tokens:  ['Это', 'Письма', 'оперы', 'Николай', 'тех']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_47.h5\n",
            "Main Epoch 48/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.4770 - acc: 0.8835 - truncated_acc: 0.7033 - truncated_loss: 1.2135 - val_loss: 0.1692 - val_acc: 0.9694 - val_truncated_acc: 0.9215 - val_truncated_loss: 0.4332\n",
            "-\n",
            "Input tokens:   ['решаФтся', 'лаза', 'П', 'назад', 'Уразом']\n",
            "Decoded tokens: ['решатся', 'лаза', 'По', 'назад', 'Уразом']\n",
            "Target tokens:  ['решается', 'глаза', 'П', 'назад', 'разом']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_48.h5\n",
            "Main Epoch 49/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4510 - acc: 0.8921 - truncated_acc: 0.7249 - truncated_loss: 1.1486 - val_loss: 0.1723 - val_acc: 0.9752 - val_truncated_acc: 0.9364 - val_truncated_loss: 0.4410\n",
            "-\n",
            "Input tokens:   ['был', 'слШились', 'их', 'акетры', 'праЩкой']\n",
            "Decoded tokens: ['был', 'слились', 'их', 'актеры', 'пракой']\n",
            "Target tokens:  ['был', 'слились', 'их', 'актеры', 'правкой']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_49.h5\n",
            "Main Epoch 50/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4436 - acc: 0.8956 - truncated_acc: 0.7341 - truncated_loss: 1.1282 - val_loss: 0.2393 - val_acc: 0.9546 - val_truncated_acc: 0.8837 - val_truncated_loss: 0.6106\n",
            "-\n",
            "Input tokens:   ['разносятся', 'он', 'рублей', 'неуюно', 'должно']\n",
            "Decoded tokens: ['разносятся', 'он', 'рублей', 'неуно', 'должно']\n",
            "Target tokens:  ['разносятся', 'он', 'рублей', 'неуютно', 'должно']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_50.h5\n",
            "Main Epoch 51/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4399 - acc: 0.8942 - truncated_acc: 0.7304 - truncated_loss: 1.1198 - val_loss: 0.1780 - val_acc: 0.9706 - val_truncated_acc: 0.9248 - val_truncated_loss: 0.4553\n",
            "-\n",
            "Input tokens:   ['полуобтинки', 'всЮе', 'полушелковаЖ', 'нчои', 'и']\n",
            "Decoded tokens: ['полуботинки', 'все', 'полушелкова', 'ночи', 'и']\n",
            "Target tokens:  ['полуботинки', 'все', 'полушелковая', 'ночи', 'и']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_51.h5\n",
            "Main Epoch 52/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4323 - acc: 0.8951 - truncated_acc: 0.7325 - truncated_loss: 1.1004 - val_loss: 0.2265 - val_acc: 0.9496 - val_truncated_acc: 0.8708 - val_truncated_loss: 0.5799\n",
            "-\n",
            "Input tokens:   ['иаче', 'нвших', 'вы', 'Чагибин', 'три']\n",
            "Decoded tokens: ['подобным', 'наших', 'вы', 'Чагибин', 'три']\n",
            "Target tokens:  ['иначе', 'наших', 'вы', 'Нагибин', 'три']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_52.h5\n",
            "Main Epoch 53/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4500 - acc: 0.8921 - truncated_acc: 0.7248 - truncated_loss: 1.1461 - val_loss: 0.2121 - val_acc: 0.9641 - val_truncated_acc: 0.9082 - val_truncated_loss: 0.5425\n",
            "-\n",
            "Input tokens:   ['ли', 'орбащает', 'руни', 'Даших', 'диет']\n",
            "Decoded tokens: ['ли', 'обращает', 'руни', 'Даших', 'дите']\n",
            "Target tokens:  ['ли', 'обращает', 'руки', 'ваших', 'идет']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_53.h5\n",
            "Main Epoch 54/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4561 - acc: 0.8910 - truncated_acc: 0.7223 - truncated_loss: 1.1606 - val_loss: 0.2013 - val_acc: 0.9605 - val_truncated_acc: 0.8987 - val_truncated_loss: 0.5151\n",
            "-\n",
            "Input tokens:   ['трупп', 'эдак', 'гроамды', 'выишвки', 'этом']\n",
            "Decoded tokens: ['трупп', 'эдак', 'громады', 'вышивки', 'этом']\n",
            "Target tokens:  ['труппы', 'эдак', 'громады', 'вышивки', 'этом']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_54.h5\n",
            "Main Epoch 55/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4519 - acc: 0.8916 - truncated_acc: 0.7236 - truncated_loss: 1.1510 - val_loss: 0.1778 - val_acc: 0.9693 - val_truncated_acc: 0.9212 - val_truncated_loss: 0.4551\n",
            "-\n",
            "Input tokens:   ['собра', 'робок', 'Е', 'сытыЕе', 'дремелт']\n",
            "Decoded tokens: ['собра', 'робок', 'Е', 'сытые', 'дремел']\n",
            "Target tokens:  ['сбора', 'робко', 'Е', 'сытые', 'дремлет']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_55.h5\n",
            "Main Epoch 56/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 67s 165ms/step - loss: 0.4299 - acc: 0.8967 - truncated_acc: 0.7367 - truncated_loss: 1.0948 - val_loss: 0.2149 - val_acc: 0.9587 - val_truncated_acc: 0.8942 - val_truncated_loss: 0.5501\n",
            "-\n",
            "Input tokens:   ['маленьские', 'ечсать', 'не', 'Режсисер', 'Чехова']\n",
            "Decoded tokens: ['маленькие', 'чесать', 'не', 'Режсисер', 'Чехова']\n",
            "Target tokens:  ['маленькие', 'чесать', 'не', 'Режиссер', 'Чехова']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_56.h5\n",
            "Main Epoch 57/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4199 - acc: 0.8999 - truncated_acc: 0.7447 - truncated_loss: 1.0695 - val_loss: 0.2034 - val_acc: 0.9626 - val_truncated_acc: 0.9041 - val_truncated_loss: 0.5209\n",
            "-\n",
            "Input tokens:   ['за', 'Биографиечская', 'да', 'мааленьких', 'деталми']\n",
            "Decoded tokens: ['за', 'Биографическая', 'да', 'маленьких', 'детали']\n",
            "Target tokens:  ['за', 'Биографическая', 'да', 'маленьких', 'деталями']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_57.h5\n",
            "Main Epoch 58/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.4359 - acc: 0.8966 - truncated_acc: 0.7364 - truncated_loss: 1.1100 - val_loss: 0.2321 - val_acc: 0.9577 - val_truncated_acc: 0.8916 - val_truncated_loss: 0.5941\n",
            "-\n",
            "Input tokens:   ['РВып', 'колйске', 'обратил', 'полаучают', 'окруЖили']\n",
            "Decoded tokens: ['Расставления', 'колоске', 'обратил', 'получают', 'окруили']\n",
            "Target tokens:  ['Вып', 'коляске', 'обратил', 'получают', 'окружили']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_58.h5\n",
            "Main Epoch 59/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4389 - acc: 0.8961 - truncated_acc: 0.7351 - truncated_loss: 1.1172 - val_loss: 0.1793 - val_acc: 0.9746 - val_truncated_acc: 0.9348 - val_truncated_loss: 0.4587\n",
            "-\n",
            "Input tokens:   ['По', 'чертят', 'приделал', 'стороны', 'дугие']\n",
            "Decoded tokens: ['По', 'чертят', 'приделал', 'стороны', 'дугие']\n",
            "Target tokens:  ['По', 'чертят', 'приделал', 'стороны', 'другие']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_59.h5\n",
            "Main Epoch 60/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4221 - acc: 0.9009 - truncated_acc: 0.7474 - truncated_loss: 1.0739 - val_loss: 0.1852 - val_acc: 0.9655 - val_truncated_acc: 0.9116 - val_truncated_loss: 0.4742\n",
            "-\n",
            "Input tokens:   ['очен', 'уЖборную', 'бойко', 'не', 'ка']\n",
            "Decoded tokens: ['очен', 'уборную', 'бойко', 'не', 'ка']\n",
            "Target tokens:  ['очень', 'уборную', 'бойко', 'не', 'ка']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_60.h5\n",
            "Main Epoch 61/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4062 - acc: 0.9033 - truncated_acc: 0.7534 - truncated_loss: 1.0340 - val_loss: 0.2170 - val_acc: 0.9579 - val_truncated_acc: 0.8921 - val_truncated_loss: 0.5555\n",
            "-\n",
            "Input tokens:   ['литератруы', 'колясак', 'искусствда', 'будьтПе', 'иду']\n",
            "Decoded tokens: ['литературы', 'коляска', 'искусства', 'будьте', 'иду']\n",
            "Target tokens:  ['литературы', 'коляска', 'искусства', 'будьте', 'идут']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_61.h5\n",
            "Main Epoch 62/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4220 - acc: 0.8988 - truncated_acc: 0.7419 - truncated_loss: 1.0749 - val_loss: 0.1789 - val_acc: 0.9651 - val_truncated_acc: 0.9106 - val_truncated_loss: 0.4581\n",
            "-\n",
            "Input tokens:   ['и', 'дло', 'пуастично', 'ЧехЦв', 'Поленека']\n",
            "Decoded tokens: ['и', 'доло', 'пустично', 'Чехов', 'Поленека']\n",
            "Target tokens:  ['и', 'дело', 'пластично', 'Чехов', 'Поленька']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_62.h5\n",
            "Main Epoch 63/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.4178 - acc: 0.9006 - truncated_acc: 0.7466 - truncated_loss: 1.0641 - val_loss: 0.1754 - val_acc: 0.9666 - val_truncated_acc: 0.9146 - val_truncated_loss: 0.4489\n",
            "-\n",
            "Input tokens:   ['вы', 'и', 'М', 'ншчало', 'уЖборную']\n",
            "Decoded tokens: ['вы', 'и', 'М', 'начало', 'уборную']\n",
            "Target tokens:  ['вы', 'и', 'М', 'начало', 'уборную']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_63.h5\n",
            "Main Epoch 64/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4121 - acc: 0.9035 - truncated_acc: 0.7542 - truncated_loss: 1.0484 - val_loss: 0.1934 - val_acc: 0.9592 - val_truncated_acc: 0.8954 - val_truncated_loss: 0.4954\n",
            "-\n",
            "Input tokens:   ['из', 'нее', 'из', 'понраивлся', 'орбащает']\n",
            "Decoded tokens: ['из', 'нее', 'из', 'понравился', 'обращает']\n",
            "Target tokens:  ['из', 'нее', 'из', 'понравился', 'обращает']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_64.h5\n",
            "Main Epoch 65/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4204 - acc: 0.8994 - truncated_acc: 0.7436 - truncated_loss: 1.0710 - val_loss: 0.1475 - val_acc: 0.9724 - val_truncated_acc: 0.9293 - val_truncated_loss: 0.3778\n",
            "-\n",
            "Input tokens:   ['сидящего', 'дв', 'не', 'же', 'нужнеЬе']\n",
            "Decoded tokens: ['сидящего', 'дв', 'не', 'же', 'нужнее']\n",
            "Target tokens:  ['сидящего', 'два', 'не', 'же', 'нужнее']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_65.h5\n",
            "Main Epoch 66/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4082 - acc: 0.9029 - truncated_acc: 0.7526 - truncated_loss: 1.0392 - val_loss: 0.1740 - val_acc: 0.9659 - val_truncated_acc: 0.9128 - val_truncated_loss: 0.4451\n",
            "-\n",
            "Input tokens:   ['нечеюм', 'верте', 'колйске', 'Вы', 'но']\n",
            "Decoded tokens: ['нечем', 'верте', 'колоске', 'Вы', 'но']\n",
            "Target tokens:  ['нечем', 'версте', 'коляске', 'Вы', 'но']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_66.h5\n",
            "Main Epoch 67/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 156ms/step - loss: 0.4302 - acc: 0.8975 - truncated_acc: 0.7387 - truncated_loss: 1.0956 - val_loss: 0.2154 - val_acc: 0.9664 - val_truncated_acc: 0.9140 - val_truncated_loss: 0.5512\n",
            "-\n",
            "Input tokens:   ['отредактироваЦнный', 'Зкоторыми', 'ыдшать', 'жалованье', 'с']\n",
            "Decoded tokens: ['отрекатированный', 'покорными', 'дышать', 'жалованье', 'с']\n",
            "Target tokens:  ['отредактированный', 'которыми', 'дышать', 'жалованье', 'с']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_67.h5\n",
            "Main Epoch 68/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4300 - acc: 0.8980 - truncated_acc: 0.7399 - truncated_loss: 1.0943 - val_loss: 0.2262 - val_acc: 0.9545 - val_truncated_acc: 0.8836 - val_truncated_loss: 0.5791\n",
            "-\n",
            "Input tokens:   ['и', 'смых', 'В', 'что', 'самого']\n",
            "Decoded tokens: ['и', 'смых', 'В', 'что', 'самого']\n",
            "Target tokens:  ['и', 'самых', 'В', 'что', 'самого']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_68.h5\n",
            "Main Epoch 69/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4197 - acc: 0.9015 - truncated_acc: 0.7488 - truncated_loss: 1.0687 - val_loss: 0.1846 - val_acc: 0.9658 - val_truncated_acc: 0.9124 - val_truncated_loss: 0.4725\n",
            "-\n",
            "Input tokens:   ['приниамется', 'поблепнела', 'в', 'хрпиит', 'страшное']\n",
            "Decoded tokens: ['принимается', 'поблепнела', 'ва', 'хрипит', 'страшное']\n",
            "Target tokens:  ['принимается', 'побледнела', 'в', 'хрипит', 'страшное']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_69.h5\n",
            "Main Epoch 70/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4261 - acc: 0.8991 - truncated_acc: 0.7427 - truncated_loss: 1.0855 - val_loss: 0.1931 - val_acc: 0.9669 - val_truncated_acc: 0.9151 - val_truncated_loss: 0.4944\n",
            "-\n",
            "Input tokens:   ['ужзе', 'обнажены', 'тлепло', 'серебряные', 'театр']\n",
            "Decoded tokens: ['уже', 'обнажены', 'телпол', 'серебряные', 'театр']\n",
            "Target tokens:  ['уже', 'обнажены', 'тепло', 'серебряные', 'театра']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_70.h5\n",
            "Main Epoch 71/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4119 - acc: 0.9006 - truncated_acc: 0.7464 - truncated_loss: 1.0494 - val_loss: 0.1969 - val_acc: 0.9635 - val_truncated_acc: 0.9066 - val_truncated_loss: 0.5040\n",
            "-\n",
            "Input tokens:   ['Татары', 'набёрежную', 'иуени', 'сУма', 'Райсакя']\n",
            "Decoded tokens: ['Татары', 'набрежную', 'изуни', 'сама', 'Райская']\n",
            "Target tokens:  ['Татары', 'набережную', 'имени', 'сама', 'Райская']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_71.h5\n",
            "Main Epoch 72/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4182 - acc: 0.9006 - truncated_acc: 0.7467 - truncated_loss: 1.0647 - val_loss: 0.1599 - val_acc: 0.9772 - val_truncated_acc: 0.9417 - val_truncated_loss: 0.4092\n",
            "-\n",
            "Input tokens:   ['выпить', 'домах', 'ужзе', 'Нео', 'Сочинения']\n",
            "Decoded tokens: ['выпить', 'домах', 'ужзе', 'Нео', 'Сочинения']\n",
            "Target tokens:  ['выпить', 'домах', 'уже', 'Небо', 'Сочинения']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_72.h5\n",
            "Main Epoch 73/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4126 - acc: 0.9023 - truncated_acc: 0.7508 - truncated_loss: 1.0515 - val_loss: 0.2007 - val_acc: 0.9611 - val_truncated_acc: 0.9003 - val_truncated_loss: 0.5139\n",
            "-\n",
            "Input tokens:   ['знаком', 'игрете', 'Ю', 'пшеком', 'жутко']\n",
            "Decoded tokens: ['знаком', 'игрете', 'Ю', 'пешком', 'жутко']\n",
            "Target tokens:  ['знаком', 'играете', 'Ю', 'пешком', 'жутко']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_73.h5\n",
            "Main Epoch 74/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4151 - acc: 0.9010 - truncated_acc: 0.7477 - truncated_loss: 1.0566 - val_loss: 0.1768 - val_acc: 0.9643 - val_truncated_acc: 0.9084 - val_truncated_loss: 0.4528\n",
            "-\n",
            "Input tokens:   ['Новое', 'Жего', 'то', 'Вокруг', 'неразлучна']\n",
            "Decoded tokens: ['Новое', 'Жего', 'то', 'Вокруг', 'неразлучна']\n",
            "Target tokens:  ['Новое', 'его', 'что', 'Вокруг', 'неразлучна']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_74.h5\n",
            "Main Epoch 75/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4358 - acc: 0.8968 - truncated_acc: 0.7369 - truncated_loss: 1.1093 - val_loss: 0.2229 - val_acc: 0.9578 - val_truncated_acc: 0.8917 - val_truncated_loss: 0.5709\n",
            "-\n",
            "Input tokens:   ['вечермего', 'внимания', 'пчоти', 'жгчуий', 'Деьица']\n",
            "Decoded tokens: ['вечерего', 'внимания', 'почти', 'желчий', 'Дельца']\n",
            "Target tokens:  ['вечернего', 'внимания', 'почти', 'жгучий', 'Девица']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_75.h5\n",
            "Main Epoch 76/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4110 - acc: 0.9013 - truncated_acc: 0.7482 - truncated_loss: 1.0469 - val_loss: 0.1713 - val_acc: 0.9725 - val_truncated_acc: 0.9296 - val_truncated_loss: 0.4380\n",
            "-\n",
            "Input tokens:   ['прихдоится', 'свевтает', 'и', 'Елена', 'гряная']\n",
            "Decoded tokens: ['приходится', 'светает', 'и', 'Елена', 'гряная']\n",
            "Target tokens:  ['приходится', 'светает', 'и', 'Елена', 'грязная']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_76.h5\n",
            "Main Epoch 77/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 65s 161ms/step - loss: 0.3910 - acc: 0.9087 - truncated_acc: 0.7672 - truncated_loss: 0.9956 - val_loss: 0.1890 - val_acc: 0.9618 - val_truncated_acc: 0.9021 - val_truncated_loss: 0.4839\n",
            "-\n",
            "Input tokens:   ['шелквым', 'маркиза', 'ЮУст', 'репетиця', 'Хорош']\n",
            "Decoded tokens: ['шелковым', 'маркиза', 'Уст', 'репетиц', 'Хорош']\n",
            "Target tokens:  ['шелковым', 'маркиза', 'Юст', 'репетиция', 'Хорош']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_77.h5\n",
            "Main Epoch 78/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4054 - acc: 0.9026 - truncated_acc: 0.7515 - truncated_loss: 1.0327 - val_loss: 0.1768 - val_acc: 0.9663 - val_truncated_acc: 0.9136 - val_truncated_loss: 0.4527\n",
            "-\n",
            "Input tokens:   ['те', 'нает', 'можон', 'и', 'из']\n",
            "Decoded tokens: ['те', 'нает', 'можен', 'и', 'из']\n",
            "Target tokens:  ['тех', 'нет', 'можно', 'и', 'из']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_78.h5\n",
            "Main Epoch 79/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4241 - acc: 0.8986 - truncated_acc: 0.7416 - truncated_loss: 1.0792 - val_loss: 0.1868 - val_acc: 0.9643 - val_truncated_acc: 0.9085 - val_truncated_loss: 0.4781\n",
            "-\n",
            "Input tokens:   ['не', 'париПка', 'дуКрацкой', 'на', 'воЫт']\n",
            "Decoded tokens: ['не', 'парика', 'дурацкой', 'на', 'вот']\n",
            "Target tokens:  ['не', 'парика', 'дурацкой', 'на', 'вот']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_79.h5\n",
            "Main Epoch 80/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.3863 - acc: 0.9085 - truncated_acc: 0.7667 - truncated_loss: 0.9838 - val_loss: 0.1754 - val_acc: 0.9666 - val_truncated_acc: 0.9145 - val_truncated_loss: 0.4488\n",
            "-\n",
            "Input tokens:   ['сцее', 'гноловы', 'загрможденность', 'репетироавть', 'звЦуки']\n",
            "Decoded tokens: ['сцее', 'головы', 'загроможденность', 'репетировать', 'звуки']\n",
            "Target tokens:  ['сцене', 'головы', 'загроможденность', 'репетировать', 'звуки']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_80.h5\n",
            "Main Epoch 81/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4409 - acc: 0.8969 - truncated_acc: 0.7371 - truncated_loss: 1.1226 - val_loss: 0.1984 - val_acc: 0.9684 - val_truncated_acc: 0.9191 - val_truncated_loss: 0.5077\n",
            "-\n",
            "Input tokens:   ['к', 'но', 'вторйо', 'тань', 'Ыто']\n",
            "Decoded tokens: ['ка', 'но', 'второй', 'тань', 'подо']\n",
            "Target tokens:  ['к', 'но', 'второй', 'ткань', 'что']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_81.h5\n",
            "Main Epoch 82/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4336 - acc: 0.8974 - truncated_acc: 0.7384 - truncated_loss: 1.1040 - val_loss: 0.1818 - val_acc: 0.9693 - val_truncated_acc: 0.9213 - val_truncated_loss: 0.4649\n",
            "-\n",
            "Input tokens:   ['бесспорно', 'СчАастливица', 'никакогЦ', 'у', 'Баиртон']\n",
            "Decoded tokens: ['бесспорно', 'Счастливица', 'никакого', 'у', 'Баритон']\n",
            "Target tokens:  ['бесспорно', 'Счастливица', 'никакого', 'у', 'Баритон']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_82.h5\n",
            "Main Epoch 83/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4154 - acc: 0.9009 - truncated_acc: 0.7474 - truncated_loss: 1.0568 - val_loss: 0.1786 - val_acc: 0.9743 - val_truncated_acc: 0.9342 - val_truncated_loss: 0.4567\n",
            "-\n",
            "Input tokens:   ['ъПыльно', 'Лица', 'Давайть', 'не', 'немилоседрно']\n",
            "Decoded tokens: ['Польно', 'Лица', 'Давать', 'не', 'немилосерд']\n",
            "Target tokens:  ['Пыльно', 'Лица', 'Давайте', 'не', 'немилосердно']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_83.h5\n",
            "Main Epoch 84/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.4057 - acc: 0.9025 - truncated_acc: 0.7514 - truncated_loss: 1.0333 - val_loss: 0.1945 - val_acc: 0.9588 - val_truncated_acc: 0.8943 - val_truncated_loss: 0.4982\n",
            "-\n",
            "Input tokens:   ['самой', 'меясц', 'но', 'Татары', 'голоБсом']\n",
            "Decoded tokens: ['самой', 'месяц', 'но', 'Татары', 'голосом']\n",
            "Target tokens:  ['самой', 'месяц', 'но', 'Татары', 'голосом']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_84.h5\n",
            "Main Epoch 85/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4244 - acc: 0.8991 - truncated_acc: 0.7428 - truncated_loss: 1.0809 - val_loss: 0.1815 - val_acc: 0.9675 - val_truncated_acc: 0.9167 - val_truncated_loss: 0.4645\n",
            "-\n",
            "Input tokens:   ['неразлучна', 'вечермего', 'На', 'девочки', 'Певичк']\n",
            "Decoded tokens: ['неразлучна', 'вечерего', 'На', 'девочки', 'Певичк']\n",
            "Target tokens:  ['неразлучна', 'вечернего', 'На', 'девочки', 'Певички']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_85.h5\n",
            "Main Epoch 86/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4052 - acc: 0.9032 - truncated_acc: 0.7531 - truncated_loss: 1.0318 - val_loss: 0.1776 - val_acc: 0.9632 - val_truncated_acc: 0.9057 - val_truncated_loss: 0.4548\n",
            "-\n",
            "Input tokens:   ['же', 'я', 'он', 'дремзты', 'голоЧса']\n",
            "Decoded tokens: ['же', 'я', 'он', 'дреметы', 'голоса']\n",
            "Target tokens:  ['же', 'я', 'он', 'дремоты', 'голоса']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_86.h5\n",
            "Main Epoch 87/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.4087 - acc: 0.9020 - truncated_acc: 0.7501 - truncated_loss: 1.0408 - val_loss: 0.1920 - val_acc: 0.9607 - val_truncated_acc: 0.8993 - val_truncated_loss: 0.4915\n",
            "-\n",
            "Input tokens:   ['БорОсов', 'великолепное', 'тлепло', 'прэходили', 'впоследствии']\n",
            "Decoded tokens: ['Боросов', 'великолепное', 'телпол', 'проходили', 'впоследствии']\n",
            "Target tokens:  ['Борисов', 'великолепное', 'тепло', 'проходили', 'впоследствии']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_87.h5\n",
            "Main Epoch 88/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4125 - acc: 0.9013 - truncated_acc: 0.7482 - truncated_loss: 1.0503 - val_loss: 0.1787 - val_acc: 0.9658 - val_truncated_acc: 0.9125 - val_truncated_loss: 0.4574\n",
            "-\n",
            "Input tokens:   ['заторно', 'легРий', 'кладетт', 'Цтеатре', 'сидтя']\n",
            "Decoded tokens: ['заторно', 'легий', 'кладет', 'Цетаре', 'сидят']\n",
            "Target tokens:  ['задорно', 'легкий', 'кладет', 'театре', 'сидят']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_88.h5\n",
            "Main Epoch 89/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.3873 - acc: 0.9100 - truncated_acc: 0.7704 - truncated_loss: 0.9867 - val_loss: 0.1689 - val_acc: 0.9664 - val_truncated_acc: 0.9139 - val_truncated_loss: 0.4326\n",
            "-\n",
            "Input tokens:   ['кЩк', 'сЖарый', 'и', 'Он', 'никакогЦ']\n",
            "Decoded tokens: ['кок', 'сарый', 'и', 'Он', 'никакого']\n",
            "Target tokens:  ['как', 'старый', 'и', 'Он', 'никакого']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_89.h5\n",
            "Main Epoch 90/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.3974 - acc: 0.9086 - truncated_acc: 0.7671 - truncated_loss: 1.0115 - val_loss: 0.1968 - val_acc: 0.9613 - val_truncated_acc: 0.9010 - val_truncated_loss: 0.5035\n",
            "-\n",
            "Input tokens:   ['в', 'десяЗтилетия', 'службы', 'чая', 'в']\n",
            "Decoded tokens: ['в', 'десятилетия', 'службы', 'чая', 'в']\n",
            "Target tokens:  ['в', 'десятилетия', 'службы', 'чая', 'в']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_90.h5\n",
            "Main Epoch 91/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4233 - acc: 0.8993 - truncated_acc: 0.7432 - truncated_loss: 1.0784 - val_loss: 0.2214 - val_acc: 0.9662 - val_truncated_acc: 0.9134 - val_truncated_loss: 0.5668\n",
            "-\n",
            "Input tokens:   ['пстреют', 'Антгоне', 'Чехо', 'кирчит', 'писаял']\n",
            "Decoded tokens: ['постреют', 'Англоне', 'Чехо', 'кричит', 'писал']\n",
            "Target tokens:  ['пестреют', 'Антоне', 'Чехов', 'кричит', 'писал']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_91.h5\n",
            "Main Epoch 92/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4358 - acc: 0.8946 - truncated_acc: 0.7313 - truncated_loss: 1.1105 - val_loss: 0.1863 - val_acc: 0.9696 - val_truncated_acc: 0.9222 - val_truncated_loss: 0.4767\n",
            "-\n",
            "Input tokens:   ['от', 'спасио', 'домах', 'аШврова', 'сиюнее']\n",
            "Decoded tokens: ['от', 'спасио', 'домах', 'Шаврова', 'синее']\n",
            "Target tokens:  ['вот', 'спасибо', 'домах', 'Шаврова', 'синее']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_92.h5\n",
            "Main Epoch 93/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 157ms/step - loss: 0.4279 - acc: 0.8985 - truncated_acc: 0.7411 - truncated_loss: 1.0902 - val_loss: 0.2016 - val_acc: 0.9610 - val_truncated_acc: 0.9001 - val_truncated_loss: 0.5161\n",
            "-\n",
            "Input tokens:   ['убль', 'Е', 'по', 'звозчик', 'Е']\n",
            "Decoded tokens: ['буль', 'Е', 'по', 'звозчик', 'Е']\n",
            "Target tokens:  ['рубль', 'Е', 'по', 'извозчик', 'Е']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_93.h5\n",
            "Main Epoch 94/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.3958 - acc: 0.9061 - truncated_acc: 0.7606 - truncated_loss: 1.0084 - val_loss: 0.1578 - val_acc: 0.9752 - val_truncated_acc: 0.9363 - val_truncated_loss: 0.4036\n",
            "-\n",
            "Input tokens:   ['налбюдений', 'сццне', 'Поелнька', 'оерелья', 'Стрйоные']\n",
            "Decoded tokens: ['наблюдений', 'сцене', 'Поленька', 'оберелья', 'Стройные']\n",
            "Target tokens:  ['наблюдений', 'сцене', 'Поленька', 'ожерелья', 'Стройные']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_94.h5\n",
            "Main Epoch 95/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.3923 - acc: 0.9064 - truncated_acc: 0.7612 - truncated_loss: 0.9994 - val_loss: 0.2242 - val_acc: 0.9547 - val_truncated_acc: 0.8840 - val_truncated_loss: 0.5741\n",
            "-\n",
            "Input tokens:   ['они', 'владееА', 'выишвки', 'выехаал', 'ремя']\n",
            "Decoded tokens: ['они', 'владеет', 'вышивки', 'выехала', 'ремя']\n",
            "Target tokens:  ['они', 'владеет', 'вышивки', 'выехала', 'время']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_95.h5\n",
            "Main Epoch 96/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 159ms/step - loss: 0.3861 - acc: 0.9102 - truncated_acc: 0.7709 - truncated_loss: 0.9833 - val_loss: 0.1661 - val_acc: 0.9682 - val_truncated_acc: 0.9185 - val_truncated_loss: 0.4250\n",
            "-\n",
            "Input tokens:   ['надежды', 'в', 'МЪне', 'Элетят', 'ножкоЯй']\n",
            "Decoded tokens: ['надежды', 'во', 'Мне', 'плетят', 'ножкой']\n",
            "Target tokens:  ['надежды', 'в', 'Мне', 'летят', 'ножкой']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_96.h5\n",
            "Main Epoch 97/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 160ms/step - loss: 0.4063 - acc: 0.9062 - truncated_acc: 0.7609 - truncated_loss: 1.0345 - val_loss: 0.1723 - val_acc: 0.9697 - val_truncated_acc: 0.9224 - val_truncated_loss: 0.4411\n",
            "-\n",
            "Input tokens:   ['ОПоленьке', 'очеьн', 'моДжет', 'репетиця', 'гримиряют']\n",
            "Decoded tokens: ['Поленьке', 'очень', 'может', 'репетиция', 'гримиряют']\n",
            "Target tokens:  ['Поленьке', 'очень', 'может', 'репетиция', 'гримируют']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_97.h5\n",
            "Main Epoch 98/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 63s 158ms/step - loss: 0.4088 - acc: 0.9039 - truncated_acc: 0.7550 - truncated_loss: 1.0408 - val_loss: 0.1510 - val_acc: 0.9717 - val_truncated_acc: 0.9274 - val_truncated_loss: 0.3866\n",
            "-\n",
            "Input tokens:   ['Он', 'измеънилась', 'ПолЫнька', 'вДном', 'знат']\n",
            "Decoded tokens: ['Он', 'изменилась', 'Поленька', 'воном', 'знат']\n",
            "Target tokens:  ['Он', 'изменилась', 'Поленька', 'вином', 'знает']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_98.h5\n",
            "Main Epoch 99/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.3977 - acc: 0.9084 - truncated_acc: 0.7664 - truncated_loss: 1.0129 - val_loss: 0.1801 - val_acc: 0.9633 - val_truncated_acc: 0.9059 - val_truncated_loss: 0.4612\n",
            "-\n",
            "Input tokens:   ['Шсвечей', 'псевдоРним', 'не', 'вкчусе', 'им']\n",
            "Decoded tokens: ['свечей', 'поведоним', 'не', 'вкуче', 'им']\n",
            "Target tokens:  ['свечей', 'псевдоним', 'не', 'вкусе', 'им']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_99.h5\n",
            "Main Epoch 100/100\n",
            "Shuffling data.\n",
            "Epoch 1/1\n",
            "402/402 [==============================] - 64s 158ms/step - loss: 0.3925 - acc: 0.9091 - truncated_acc: 0.7681 - truncated_loss: 0.9999 - val_loss: 0.1753 - val_acc: 0.9638 - val_truncated_acc: 0.9073 - val_truncated_loss: 0.4488\n",
            "-\n",
            "Input tokens:   ['а', 'камняни', 'рукопиней', 'Быстло', 'гноловы']\n",
            "Decoded tokens: ['а', 'камняни', 'рукопиней', 'Быстло', 'головы']\n",
            "Target tokens:  ['а', 'камнями', 'рукописей', 'Быстро', 'головы']\n",
            "-\n",
            "Saving full model to checkpoints/seq2seq_epoch_100.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0gu1sMA0uvFe",
        "colab_type": "code",
        "outputId": "2a22a30a-5bea-407d-a2c4-a980389de9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# from utils import CharacterTable, transform\n",
        "# from utils import restore_model, decode_sequences\n",
        "# from utils import read_text, tokenize\n",
        "\n",
        "error_rate = 0.6\n",
        "reverse = True\n",
        "model_path = 'checkpoints/seq2seq_epoch_100.h5'\n",
        "hidden_size = 512\n",
        "sample_mode = 'argmax'\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/RUSbooks' \n",
        "books = ['txt3.txt','txt4.txt','txt5.txt','txt6.txt','txt7.txt',\n",
        "               'txt8.txt','txt9.txt','txt11.txt','txt12.txt']\n",
        "# val_books = ['txt5.txt']\n",
        "test_sentence = 'Здравствуйте меня зовут Димаш. Сегодня я сижу на стажировке и запускаю модель'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text  = read_text(data_path, books)\n",
        "    vocab = tokenize(text)\n",
        "    vocab = list(filter(None, set(vocab)))\n",
        "    # `maxlen` is the length of the longest word in the vocabulary\n",
        "    # plus two SOS and EOS characters.\n",
        "    maxlen = max([len(token) for token in vocab]) + 2\n",
        "    train_encoder, train_decoder, train_target = transform(\n",
        "        vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
        "\n",
        "    tokens = tokenize(test_sentence)\n",
        "    tokens = list(filter(None, tokens))\n",
        "    nb_tokens = len(tokens)\n",
        "    misspelled_tokens, _, target_tokens = transform(\n",
        "        tokens, maxlen, error_rate=error_rate, shuffle=False)\n",
        "\n",
        "    input_chars = set(' '.join(train_encoder))\n",
        "    target_chars = set(' '.join(train_decoder))\n",
        "    input_ctable = CharacterTable(input_chars)\n",
        "    target_ctable = CharacterTable(target_chars)\n",
        "    \n",
        "    encoder_model, decoder_model = restore_model(model_path, hidden_size)\n",
        "    \n",
        "    input_tokens, target_tokens, decoded_tokens = decode_sequences(\n",
        "        misspelled_tokens, target_tokens, input_ctable, target_ctable,\n",
        "        maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
        "        sample_mode=sample_mode, random=False)\n",
        "    \n",
        "    print('-')\n",
        "    print('Input sentence:  ', ' '.join([token for token in input_tokens]))\n",
        "    print('-')\n",
        "    print('Decoded sentence:', ' '.join([token for token in decoded_tokens]))\n",
        "    print('-')\n",
        "    print('Target sentence: ', ' '.join([token for token in target_tokens]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence:   Здрвствуйте меня зовут Димаф Сегодня я сиыу на стажировке и запусчкаю модеьл\n",
            "-\n",
            "Decoded sentence: Здравствуйте меня зовут Димао Сегодня я силу на старичовке и запускаю модель\n",
            "-\n",
            "Target sentence:  Здравствуйте меня зовут Димаш Сегодня я сижу на стажировке и запускаю модель\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjkruRFPc4JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "14BVcXUZCkKM",
        "colab_type": "code",
        "outputId": "fb43a8a7-fbd7-4ee5-8d5f-490d82357c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# from utils import CharacterTable, transform\n",
        "# from utils import restore_model, decode_sequences\n",
        "# from utils import read_text, tokenize\n",
        "\n",
        "error_rate = 0.6\n",
        "reverse = True\n",
        "model_path = 'checkpoints/seq2seq_epoch_100.h5'\n",
        "hidden_size = 512\n",
        "sample_mode = 'argmax'\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/RUSbooks' \n",
        "books = ['txt3.txt','txt4.txt','txt5.txt','txt6.txt','txt7.txt',\n",
        "               'txt8.txt','txt9.txt','txt11.txt','txt12.txt']\n",
        "\n",
        "test_sentence = input(\"Enter any text: \")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text  = read_text(data_path, books)\n",
        "    vocab = tokenize(text)\n",
        "    vocab = list(filter(None, set(vocab)))\n",
        "    # `maxlen` is the length of the longest word in the vocabulary\n",
        "    # plus two SOS and EOS characters.\n",
        "    maxlen = max([len(token) for token in vocab]) + 2\n",
        "    train_encoder, train_decoder, train_target = transform(vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
        "\n",
        "    tokens = tokenize(test_sentence)\n",
        "    tokens = list(filter(None, tokens))\n",
        "    nb_tokens = len(tokens)\n",
        "    _, _, target_tokens = transform(tokens, maxlen, error_rate=error_rate, shuffle=False)\n",
        "\n",
        "    \n",
        "    input_chars = set(' '.join(train_encoder))\n",
        "    target_chars = set(' '.join(train_decoder))\n",
        "    input_ctable = CharacterTable(input_chars)\n",
        "\n",
        "    target_ctable = CharacterTable(target_chars) \n",
        "    \n",
        "    encoder_model, decoder_model = restore_model(model_path, hidden_size)\n",
        "    start_time = time.clock()\n",
        "    input_tokens, _, decoded_tokens = decode_sequences(target_tokens, target_tokens, input_ctable, target_ctable,\n",
        "        maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
        "        sample_mode=sample_mode, random=False)\n",
        "    print(time.clock() - start_time, \"seconds\")\n",
        "    \n",
        "    print('Maybe you meant:', ' '.join([token for token in decoded_tokens]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter any text: скачатрь игрук онлайн на ноутбок без регистрации\n",
            "4.357222999999067 seconds\n",
            "Maybe you meant: скачать игрук отлане на ноуток без регистрации\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ta7tioB4eT46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}